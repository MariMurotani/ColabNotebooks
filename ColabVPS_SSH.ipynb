{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOn5BEL3AvCWZGwweChow95",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MariMurotani/ColabNotebooks/blob/main/ColabVPS_SSH.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrXloxzymdzF",
        "outputId": "f0addb97-389c-4c8d-9689-344e881cf1fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import io"
      ],
      "metadata": {
        "id": "zizBCiHymfyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. SSHとNgrokのセットアップ\n",
        "!apt-get install -qq -o=Dpkg::Use-Pty=0 openssh-server\n",
        "!pip install -q pyngrok\n",
        "\n",
        "# 2. SSHサーバー設定\n",
        "!mkdir -p /var/run/sshd\n",
        "!echo 'PermitRootLogin yes' >> /etc/ssh/sshd_config\n",
        "!echo 'PasswordAuthentication yes' >> /etc/ssh/sshd_config\n",
        "!echo 'root:password' | chpasswd"
      ],
      "metadata": {
        "id": "XczIx1KBmaLr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c8c9e69-c9ca-4dde-fce2-92aa4af413dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package openssh-sftp-server.\n",
            "(Reading database ... 126101 files and directories currently installed.)\n",
            "Preparing to unpack .../openssh-sftp-server_1%3a8.9p1-3ubuntu0.13_amd64.deb ...\n",
            "Unpacking openssh-sftp-server (1:8.9p1-3ubuntu0.13) ...\n",
            "Selecting previously unselected package libwrap0:amd64.\n",
            "Preparing to unpack .../libwrap0_7.6.q-31build2_amd64.deb ...\n",
            "Unpacking libwrap0:amd64 (7.6.q-31build2) ...\n",
            "Selecting previously unselected package openssh-server.\n",
            "Preparing to unpack .../openssh-server_1%3a8.9p1-3ubuntu0.13_amd64.deb ...\n",
            "Unpacking openssh-server (1:8.9p1-3ubuntu0.13) ...\n",
            "Selecting previously unselected package ncurses-term.\n",
            "Preparing to unpack .../ncurses-term_6.3-2ubuntu0.1_all.deb ...\n",
            "Unpacking ncurses-term (6.3-2ubuntu0.1) ...\n",
            "Selecting previously unselected package ssh-import-id.\n",
            "Preparing to unpack .../ssh-import-id_5.11-0ubuntu1_all.deb ...\n",
            "Unpacking ssh-import-id (5.11-0ubuntu1) ...\n",
            "Setting up openssh-sftp-server (1:8.9p1-3ubuntu0.13) ...\n",
            "Setting up ssh-import-id (5.11-0ubuntu1) ...\n",
            "Setting up libwrap0:amd64 (7.6.q-31build2) ...\n",
            "Setting up ncurses-term (6.3-2ubuntu0.1) ...\n",
            "Setting up openssh-server (1:8.9p1-3ubuntu0.13) ...\n",
            "\n",
            "Creating config file /etc/ssh/sshd_config with new version\n",
            "Creating SSH2 RSA key; this may take some time ...\n",
            "3072 SHA256:lCStfAf9THnikYtdsceajdII00sD/XiutZvq6LAkJos root@4b864abc5672 (RSA)\n",
            "Creating SSH2 ECDSA key; this may take some time ...\n",
            "256 SHA256:RLh9Bnu4dlk0xSWxet1n1KsQ+OOqjwWbQIb1lNOGoX8 root@4b864abc5672 (ECDSA)\n",
            "Creating SSH2 ED25519 key; this may take some time ...\n",
            "256 SHA256:ncZXtAWBlaUdX0+p4cNaSglqvCd2tAEOn4WGdhIlBaU root@4b864abc5672 (ED25519)\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Created symlink /etc/systemd/system/sshd.service → /lib/systemd/system/ssh.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/ssh.service → /lib/systemd/system/ssh.service.\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. 公開鍵をrootユーザーのauthorized_keysに設定\n",
        "!mkdir -p /root/.ssh\n",
        "# ここにあなたのローカルのid_rsa.pubの中身を貼ってね（\"\"の中身を書き換える）\n",
        "public_key = userdata.get(\"SSH_PUB_KEY\")\n",
        "with open(\"/root/.ssh/authorized_keys\", \"w\") as f:\n",
        "    f.write(public_key)"
      ],
      "metadata": {
        "id": "qRpmuTa4mbZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hLqE80yMjAi",
        "outputId": "65a6af13-080c-4ae6-858c-57cb98b1eaf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NgrokTunnel: \"tcp://6.tcp.ngrok.io:13552\" -> \"localhost:22\"\n"
          ]
        }
      ],
      "source": [
        "# 4. Ngrokでトンネリング（無料アカウント必要）\n",
        "from pyngrok import conf, ngrok\n",
        "conf.get_default().auth_token =userdata.get(\"NGROK_TOKEN\")\n",
        "ssh_tunnel = ngrok.connect(22, \"tcp\")\n",
        "print(ssh_tunnel)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SSHフォルダを作る\n",
        "!mkdir -p /root/.ssh\n",
        "\n",
        "import textwrap\n",
        "\n",
        "# 🔐 鍵の取得と整形（改行を維持）\n",
        "private_key = textwrap.dedent(userdata.get(\"GIT_SECRET_KEY\")).strip() + \"\\n\"\n",
        "\n",
        "# 🔧 SSHディレクトリの作成\n",
        "!mkdir -p /root/.ssh\n",
        "\n",
        "# 🔐 ファイルに保存\n",
        "with open('/root/.ssh/id_rsa', 'w') as f:\n",
        "    f.write(private_key)\n",
        "\n",
        "# 🔐 パーミッション\n",
        "!chmod 600 /root/.ssh/id_rsa"
      ],
      "metadata": {
        "id": "TnQZ890_hBE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SSHサーバー設定の変更\n",
        "!sed -i 's/^#\\?PasswordAuthentication.*/PasswordAuthentication no/' /etc/ssh/sshd_config\n",
        "!sed -i 's/^#\\?ChallengeResponseAuthentication.*/ChallengeResponseAuthentication no/' /etc/ssh/sshd_config\n",
        "!sed -i 's/^#\\?PermitRootLogin.*/PermitRootLogin prohibit-password/' /etc/ssh/sshd_config\n",
        "!ssh-keyscan github.com >> /root/.ssh/known_hosts\n",
        "!service ssh restart"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_sZdHBy9Sah",
        "outputId": "7dbc5108-ef26-49c4-9021-273cd5436817"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# github.com:22 SSH-2.0-4ad6872a\n",
            "# github.com:22 SSH-2.0-4ad6872a\n",
            "# github.com:22 SSH-2.0-4ad6872a\n",
            "# github.com:22 SSH-2.0-4ad6872a\n",
            "# github.com:22 SSH-2.0-4ad6872a\n",
            " * Restarting OpenBSD Secure Shell server sshd\n",
            "   ...done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ln -s \"/content/drive/MyDrive/Colab Notebooks/ColabVPS_SSH\" ./\n",
        "%cd ColabVPS_SSH"
      ],
      "metadata": {
        "id": "70xz6yganrby",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3bf1f50-f24c-4ae9-8838-238ef0251b44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/ColabVPS_SSH\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo 'cd \"/content/drive/MyDrive/Colab Notebooks/ColabVPS_SSH\"' >> /root/.bashrc"
      ],
      "metadata": {
        "id": "mswtqYsaItrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone git@github.com:MariMurotani/ColabImageProcessing.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuBAumjNRSAp",
        "outputId": "7a4ea981-a8ad-4d9c-8963-e55ead6c0227"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'ColabImageProcessing' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Git default config\n",
        "!git config --global user.email \"mari@example.com\"\n",
        "!git config --global user.name \"Mari\""
      ],
      "metadata": {
        "id": "2MbonY7sYVEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "Vke562EUF3Ez",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1594960f-f29e-43ab-9b94-56d5747f9f25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Apr 29 04:19:47 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "print(\"Device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"N/A\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtjTbknhjJqh",
        "outputId": "db37ec2b-9124-43e9-81d6-b104e7f4d4bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.6.0+cu124\n",
            "CUDA available: True\n",
            "Device: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For pytouch 2.x\n",
        "#import os\n",
        "#os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "import os\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:512\""
      ],
      "metadata": {
        "id": "_S31zKlSspv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks/ColabVPS_SSH/ColabImageProcessing\n",
        "# Instrall for Clorify\n",
        "!sh install_colorize.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jt3m-JgAVeC9",
        "outputId": "0a34321a-3eb1-413c-b441-5e533fc49408"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/ColabVPS_SSH/ColabImageProcessing\n",
            "/content/drive/MyDrive/Colab Notebooks/ColabVPS_SSH/ColabImageProcessing\n",
            "🔧 Cloning DeOldify...\n",
            "✅ 'DeOldify' already exists. Skipping clone.\n",
            "📁 Creating models directory...\n",
            "⬇️ Preparing DeOldify pretrained model files...\n",
            "✅ ColorizeArtistic_gen.pth already exists, skipping download.\n",
            "✅ ColorizeStable_gen.pth already exists, skipping download.\n",
            "✅ DeOldify installation complete!\n",
            "👉 Put grayscale images in DeOldify/test_images/ and run your colorizer script.\n",
            "🔧 Cloning SwinIR...\n",
            "✅ 'SwinIR' already exists. Skipping clone.\n",
            "📁 Creating model_zoo directory...\n",
            "⬇️ Preparing SwinIR x2 model checkpoint...\n",
            "✅ model_zoo/001_classicalSR_DF2K_s64w8_SwinIR-M_x2.pth already exists, skipping download.\n",
            "🧰 Install dependency...\n",
            "Collecting torch==2.0.1 (from -r requirements_colorize.txt (line 1))\n",
            "  Using cached torch-2.0.1-cp311-cp311-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Collecting torchvision==0.15.2 (from -r requirements_colorize.txt (line 2))\n",
            "  Using cached torchvision-0.15.2-cp311-cp311-manylinux1_x86_64.whl.metadata (11 kB)\n",
            "Collecting numpy==1.26.4 (from -r requirements_colorize.txt (line 3))\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (from -r requirements_colorize.txt (line 4)) (1.0.15)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from -r requirements_colorize.txt (line 5)) (4.11.0.86)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from -r requirements_colorize.txt (line 6)) (1.15.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from -r requirements_colorize.txt (line 7)) (11.2.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r requirements_colorize.txt (line 8)) (4.67.1)\n",
            "Collecting fastai==1.0.61 (from -r requirements_colorize.txt (line 9))\n",
            "  Using cached fastai-1.0.61-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting ffmpeg-python (from -r requirements_colorize.txt (line 10))\n",
            "  Using cached ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting yt-dlp (from -r requirements_colorize.txt (line 11))\n",
            "  Using cached yt_dlp-2025.3.31-py3-none-any.whl.metadata (172 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->-r requirements_colorize.txt (line 1)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->-r requirements_colorize.txt (line 1)) (4.13.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->-r requirements_colorize.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->-r requirements_colorize.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->-r requirements_colorize.txt (line 1)) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1->-r requirements_colorize.txt (line 1))\n",
            "  Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1->-r requirements_colorize.txt (line 1))\n",
            "  Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1->-r requirements_colorize.txt (line 1))\n",
            "  Using cached nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1->-r requirements_colorize.txt (line 1))\n",
            "  Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1->-r requirements_colorize.txt (line 1))\n",
            "  Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.1->-r requirements_colorize.txt (line 1))\n",
            "  Using cached nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1->-r requirements_colorize.txt (line 1))\n",
            "  Using cached nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1->-r requirements_colorize.txt (line 1))\n",
            "  Using cached nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1->-r requirements_colorize.txt (line 1))\n",
            "  Using cached nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1->-r requirements_colorize.txt (line 1))\n",
            "  Using cached nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1->-r requirements_colorize.txt (line 1))\n",
            "  Using cached nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.0.0 (from torch==2.0.1->-r requirements_colorize.txt (line 1))\n",
            "  Using cached triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.2->-r requirements_colorize.txt (line 2)) (2.32.3)\n",
            "Requirement already satisfied: bottleneck in /usr/local/lib/python3.11/dist-packages (from fastai==1.0.61->-r requirements_colorize.txt (line 9)) (1.4.2)\n",
            "Requirement already satisfied: fastprogress>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from fastai==1.0.61->-r requirements_colorize.txt (line 9)) (1.0.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from fastai==1.0.61->-r requirements_colorize.txt (line 9)) (4.13.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from fastai==1.0.61->-r requirements_colorize.txt (line 9)) (3.10.0)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.11/dist-packages (from fastai==1.0.61->-r requirements_colorize.txt (line 9)) (2.10.2)\n",
            "Collecting nvidia-ml-py3 (from fastai==1.0.61->-r requirements_colorize.txt (line 9))\n",
            "  Using cached nvidia-ml-py3-7.352.0.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from fastai==1.0.61->-r requirements_colorize.txt (line 9)) (2.2.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from fastai==1.0.61->-r requirements_colorize.txt (line 9)) (24.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from fastai==1.0.61->-r requirements_colorize.txt (line 9)) (6.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->-r requirements_colorize.txt (line 1)) (75.2.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->-r requirements_colorize.txt (line 1)) (0.45.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1->-r requirements_colorize.txt (line 1)) (3.31.6)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.1->-r requirements_colorize.txt (line 1))\n",
            "  Using cached lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm->-r requirements_colorize.txt (line 4)) (0.30.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm->-r requirements_colorize.txt (line 4)) (0.5.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from ffmpeg-python->-r requirements_colorize.txt (line 10)) (1.0.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->fastai==1.0.61->-r requirements_colorize.txt (line 9)) (2.7)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm->-r requirements_colorize.txt (line 4)) (2025.3.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.1->-r requirements_colorize.txt (line 1)) (3.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fastai==1.0.61->-r requirements_colorize.txt (line 9)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fastai==1.0.61->-r requirements_colorize.txt (line 9)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fastai==1.0.61->-r requirements_colorize.txt (line 9)) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fastai==1.0.61->-r requirements_colorize.txt (line 9)) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fastai==1.0.61->-r requirements_colorize.txt (line 9)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fastai==1.0.61->-r requirements_colorize.txt (line 9)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->fastai==1.0.61->-r requirements_colorize.txt (line 9)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->fastai==1.0.61->-r requirements_colorize.txt (line 9)) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2->-r requirements_colorize.txt (line 2)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2->-r requirements_colorize.txt (line 2)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2->-r requirements_colorize.txt (line 2)) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2->-r requirements_colorize.txt (line 2)) (2025.1.31)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.1->-r requirements_colorize.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->fastai==1.0.61->-r requirements_colorize.txt (line 9)) (1.17.0)\n",
            "Using cached torch-2.0.1-cp311-cp311-manylinux1_x86_64.whl (619.9 MB)\n",
            "Using cached torchvision-0.15.2-cp311-cp311-manylinux1_x86_64.whl (6.0 MB)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Using cached fastai-1.0.61-py3-none-any.whl (239 kB)\n",
            "Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "Using cached nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
            "Using cached nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "Using cached nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "Using cached nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "Using cached nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "Using cached nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "Using cached triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "Using cached ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Using cached yt_dlp-2025.3.31-py3-none-any.whl (3.2 MB)\n",
            "Using cached lit-18.1.8-py3-none-any.whl (96 kB)\n",
            "Building wheels for collected packages: nvidia-ml-py3\n",
            "  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-py3-none-any.whl size=19172 sha256=0da57cc93db5353ceec4c11ce8c48dbcaae75a818f2d8b8c1626cc845f9dda13\n",
            "  Stored in directory: /root/.cache/pip/wheels/47/50/9e/29dc79037d74c3c1bb4a8661fb608e8674b7e4260d6a3f8f51\n",
            "Successfully built nvidia-ml-py3\n",
            "Installing collected packages: nvidia-ml-py3, lit, yt-dlp, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, numpy, ffmpeg-python, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, torchvision, fastai\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "  Attempting uninstall: fastai\n",
            "    Found existing installation: fastai 2.7.19\n",
            "    Uninstalling fastai-2.7.19:\n",
            "      Successfully uninstalled fastai-2.7.19\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed fastai-1.0.61 ffmpeg-python-0.2.0 lit-18.1.8 numpy-1.26.4 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-ml-py3-7.352.0 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.1 torchvision-0.15.2 triton-2.0.0 yt-dlp-2025.3.31\n",
            "✅ SwinIR installation complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print('torch.cuda.is_available():', torch.cuda.is_available())\n",
        "!nvidia-smi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGtQnOKz1V5M",
        "outputId": "2754f5f1-a539-470d-e59f-fd6433ddddc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.cuda.is_available(): True\n",
            "Tue Apr 29 04:36:52 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8             10W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Clorify Example\n",
        "%cd /content/ColabVPS_SSH/ColabImageProcessing/\n",
        "\n",
        "# !python app.py --images life20.jpg life19.jpg\n",
        "!python colorize.py --images life21.jpg"
      ],
      "metadata": {
        "id": "hrnjMq9JrPcr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d26db0ba-c65b-40c5-b6c0-ed65da9c0f5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/ColabVPS_SSH/ColabImageProcessing\n",
            "/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "NumExpr defaulting to 8 threads.\n",
            "CUDA:  False\n",
            "🔲 スーパーレゾリューション完了: input_images/scale_life21.jpg\n",
            "[SafeDeOldify] Using device: cpu\n",
            "/content/drive/MyDrive/Colab Notebooks/ColabVPS_SSH/ColabImageProcessing/DeOldify/fastai/data_block.py:451: UserWarning: Your training set is empty. If this is by design, pass `ignore_empty=True` to remove this warning.\n",
            "  warn(\"Your training set is empty. If this is by design, pass `ignore_empty=True` to remove this warning.\")\n",
            "/content/drive/MyDrive/Colab Notebooks/ColabVPS_SSH/ColabImageProcessing/DeOldify/fastai/data_block.py:453: UserWarning: Your validation set is empty. If this is by design, use `split_none()`\n",
            "                 or pass `ignore_empty=True` when labelling to remove this warning.\n",
            "  warn(\"\"\"Your validation set is empty. If this is by design, use `split_none()`\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "[SafeDeOldify] 🎨 Colorizing life21.jpg (render_factor=35)\n",
            "[ WARN:0@16.764] global loadsave.cpp:268 findDecoder imread_('./resource_images/watermark.png'): can't open/read file: check file path/integrity\n",
            "[SafeDeOldify] ✅ カラー化完了: life21.jpg → result_images\n",
            "🎉 パイプライン完了： DeOldify\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ws0Laufq-W7-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}