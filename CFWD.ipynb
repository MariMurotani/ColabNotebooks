{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOtSj4H9WmlnlvxTw1Liur2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MariMurotani/ColabNotebooks/blob/main/CFWD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNimchwxOYRn",
        "outputId": "e11dcf98-2c4c-4516-c09f-64c263b76422"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks/CFWD"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZAiIWBJOgJO",
        "outputId": "25b6b3b8-767e-43d7-ac44-727e696400a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/CFWD\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/He-Jinhong/CFWD.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0q3sxRgTOlAj",
        "outputId": "e3efb21c-82db-401b-a9c9-0a55870aeb0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'CFWD' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd CFWD"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_LMyygYOqEt",
        "outputId": "c21ff4de-5498-4d80-eaf3-90811d5b1e4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/CFWD/CFWD\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE: 単語のペアのモデルと2種類あるからどっちかよく確認した方がいい\n",
        "#!gdown --id 1KaeDDTPQWB9YgFjbYFmO9H_5hKrHTCNd -O pretrain_models/CFWD_LOLv1.pth\n",
        "!gdown --id 1dmu3udLbBKSuD26McYFPeqkNGEX4IuE1 -O pretrain_models/CFWD_LOLv1.pth\n",
        "\n",
        "# https://drive.google.com/file/d/1KaeDDTPQWB9YgFjbYFmO9H_5hKrHTCNd/view\n",
        "# https://drive.google.com/file/d/1KaeDDTPQWB9YgFjbYFmO9H_5hKrHTCNd/view\n",
        "# https://drive.google.com/file/d/1dmu3udLbBKSuD26McYFPeqkNGEX4IuE1/view"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlfr4HTrXpSi",
        "outputId": "3af5e500-1703-4ef5-e31f-caac7824cf2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1dmu3udLbBKSuD26McYFPeqkNGEX4IuE1\n",
            "From (redirected): https://drive.google.com/uc?id=1dmu3udLbBKSuD26McYFPeqkNGEX4IuE1&confirm=t&uuid=c774ffce-6dd1-4cf9-8362-82ac56b13ddb\n",
            "To: /content/drive/MyDrive/Colab Notebooks/CFWD/CFWD/pretrain_models/CFWD_LOLv1.pth\n",
            "100% 354M/354M [00:02<00:00, 118MB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "eeavWF97Hb8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ❌ Colabプリインストール版を完全に削除\n",
        "!pip uninstall -y numpy tensorboard tensorboard-data-server tb-nightly"
      ],
      "metadata": {
        "id": "pzHnd-uQCzOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ 安定バージョンを明示的にインストール\n",
        "!pip install numpy==1.24.4\n",
        "!pip install torch==2.0.1 torchvision==0.15.2 --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install git+https://github.com/openai/CLIP.git\n",
        "!pip install einops timm==0.9.2 opencv-python scikit-image PyWavelets pytorch-msssim ftfy Pillow==9.5.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tGiBsty1-J6C",
        "outputId": "6d377539-49e7-4884-eb74-314207bcaddd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.24.4 in /usr/local/lib/python3.11/dist-packages (1.24.4)\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Collecting torch==2.0.1\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.0.1%2Bcu118-cp311-cp311-linux_x86_64.whl (2267.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.15.2\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.15.2%2Bcu118-cp311-cp311-linux_x86_64.whl (6.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m126.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (4.13.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.1.6)\n",
            "Collecting triton==2.0.0 (from torch==2.0.1)\n",
            "  Downloading https://download.pytorch.org/whl/triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.2) (1.24.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.2) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.2) (11.2.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1) (3.31.6)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.1)\n",
            "  Downloading https://download.pytorch.org/whl/lit-15.0.7.tar.gz (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.1) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2) (2025.4.26)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.1) (1.3.0)\n",
            "Building wheels for collected packages: lit\n",
            "  Building wheel for lit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lit: filename=lit-15.0.7-py3-none-any.whl size=89990 sha256=c7e74ca39046811447436076e53c0979a35e3d05bfbed8407e6e6f64e81c7d95\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/5d/45/34fe9945d5e45e261134e72284395be36c2d4828af38e2b0fe\n",
            "Successfully built lit\n",
            "Installing collected packages: lit, triton, torch, torchvision\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.0.1+cu118 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed lit-15.0.7 torch-2.0.1+cu118 torchvision-0.15.2+cu118 triton-2.0.0\n",
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-k_01_qv2\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-k_01_qv2\n",
            "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ftfy (from clip==1.0)\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (24.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (4.67.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (0.15.2+cu118)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->clip==1.0) (0.2.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (4.13.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.1.6)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch->clip==1.0) (3.31.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch->clip==1.0) (15.0.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->clip==1.0) (1.24.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision->clip==1.0) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->clip==1.0) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->clip==1.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision->clip==1.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision->clip==1.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision->clip==1.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision->clip==1.0) (2025.4.26)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch->clip==1.0) (1.3.0)\n",
            "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: clip\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369490 sha256=f22c4e3e32c026f49f82dd3f4a67d585118b35a8247c6c8e15902d5e2fa261b9\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-rx7qbbzl/wheels/3f/7c/a4/9b490845988bf7a4db33674d52f709f088f64392063872eb9a\n",
            "Successfully built clip\n",
            "Installing collected packages: ftfy, clip\n",
            "Successfully installed clip-1.0 ftfy-6.3.1\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.1)\n",
            "Collecting timm==0.9.2\n",
            "  Downloading timm-0.9.2-py3-none-any.whl.metadata (68 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.5/68.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.11/dist-packages (1.8.0)\n",
            "Collecting pytorch-msssim\n",
            "  Downloading pytorch_msssim-1.0.0-py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.11/dist-packages (6.3.1)\n",
            "Collecting Pillow==9.5.0\n",
            "  Downloading Pillow-9.5.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.11/dist-packages (from timm==0.9.2) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm==0.9.2) (0.15.2+cu118)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm==0.9.2) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from timm==0.9.2) (0.31.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm==0.9.2) (0.5.3)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (1.24.4)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (1.15.3)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (3.4.2)\n",
            "INFO: pip is looking at multiple versions of scikit-image to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting scikit-image\n",
            "  Downloading scikit_image-0.25.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "  Downloading scikit_image-0.25.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "  Downloading scikit_image-0.24.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2025.5.10)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (0.4)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy) (0.2.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->timm==0.9.2) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->timm==0.9.2) (4.13.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->timm==0.9.2) (1.13.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->timm==0.9.2) (3.1.6)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7->timm==0.9.2) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch>=1.7->timm==0.9.2) (3.31.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch>=1.7->timm==0.9.2) (15.0.7)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->timm==0.9.2) (2025.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->timm==0.9.2) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->timm==0.9.2) (4.67.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.7->timm==0.9.2) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->timm==0.9.2) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->timm==0.9.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->timm==0.9.2) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->timm==0.9.2) (2025.4.26)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.7->timm==0.9.2) (1.3.0)\n",
            "Downloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Pillow-9.5.0-cp311-cp311-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m106.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_image-0.24.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.9/14.9 MB\u001b[0m \u001b[31m116.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_msssim-1.0.0-py3-none-any.whl (7.7 kB)\n",
            "Installing collected packages: Pillow, scikit-image, timm, pytorch-msssim\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: pillow 11.2.1\n",
            "    Uninstalling pillow-11.2.1:\n",
            "      Successfully uninstalled pillow-11.2.1\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.25.2\n",
            "    Uninstalling scikit-image-0.25.2:\n",
            "      Successfully uninstalled scikit-image-0.25.2\n",
            "  Attempting uninstall: timm\n",
            "    Found existing installation: timm 1.0.15\n",
            "    Uninstalling timm-1.0.15:\n",
            "      Successfully uninstalled timm-1.0.15\n",
            "Successfully installed Pillow-9.5.0 pytorch-msssim-1.0.0 scikit-image-0.24.0 timm-0.9.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              },
              "id": "21dc5379c97c4e359527a0ad8cdb197a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks/CFWD/CFWD"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxvuLK3vZe3K",
        "outputId": "5357f4ba-91ce-4261-ec6b-7cc3eec1fc01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/CFWD/CFWD\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from models.ddm import DenoisingDiffusion\n",
        "import torch\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "import yaml\n",
        "import argparse\n",
        "import os"
      ],
      "metadata": {
        "id": "sq-9M0FWZJAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dict2namespace(config_dict):\n",
        "    namespace = argparse.Namespace()\n",
        "    for k, v in config_dict.items():\n",
        "        setattr(namespace, k, dict2namespace(v) if isinstance(v, dict) else v)\n",
        "    return namespace"
      ],
      "metadata": {
        "id": "rP7EBBwOGvaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 推論用モデルの準備\n",
        "args = argparse.Namespace(resume='pretrain_models/CFWD_LOLv1.pth', sampling_timesteps=10, image_folder='')\n",
        "# YAMLファイル読み込み\n",
        "with open('configs/LOLv1.yml', 'r') as f:\n",
        "    config_dict = yaml.safe_load(f)\n",
        "\n",
        "config = dict2namespace(config_dict)\n",
        "config.device = torch.device(\"cuda\")\n",
        "\n",
        "model = DenoisingDiffusion(args, config)\n",
        "model.load_ddm_ckpt(args.resume, ema=True)\n",
        "model.model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Po_D8eq6GMH2",
        "outputId": "2842b9f1-59c8-4f8c-f823-ccb62ee3e0db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load checkpoint:  True\n",
            "Current checkpoint: pretrain_models/CFWD_LOLv1.pth\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataParallel(\n",
              "  (module): Net(\n",
              "    (high_enhance0): HFRM(\n",
              "      (conv_head): Depth_conv(\n",
              "        (depth_conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3)\n",
              "        (point_conv): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "      (dilated_block_LH): Dilated_Resblock(\n",
              "        (model): Sequential(\n",
              "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): LeakyReLU(negative_slope=0.01)\n",
              "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "          (3): LeakyReLU(negative_slope=0.01)\n",
              "          (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))\n",
              "          (5): LeakyReLU(negative_slope=0.01)\n",
              "          (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "          (7): LeakyReLU(negative_slope=0.01)\n",
              "          (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (dilated_block_HL): Dilated_Resblock(\n",
              "        (model): Sequential(\n",
              "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): LeakyReLU(negative_slope=0.01)\n",
              "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "          (3): LeakyReLU(negative_slope=0.01)\n",
              "          (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))\n",
              "          (5): LeakyReLU(negative_slope=0.01)\n",
              "          (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "          (7): LeakyReLU(negative_slope=0.01)\n",
              "          (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (cross_attention0): cross_attention(\n",
              "        (query): Depth_conv(\n",
              "          (depth_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
              "          (point_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (key): Depth_conv(\n",
              "          (depth_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
              "          (point_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (value): Depth_conv(\n",
              "          (depth_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
              "          (point_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (dilated_block_HH): Dilated_Resblock(\n",
              "        (model): Sequential(\n",
              "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): LeakyReLU(negative_slope=0.01)\n",
              "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "          (3): LeakyReLU(negative_slope=0.01)\n",
              "          (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))\n",
              "          (5): LeakyReLU(negative_slope=0.01)\n",
              "          (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "          (7): LeakyReLU(negative_slope=0.01)\n",
              "          (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (conv_HH): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (cross_attention1): cross_attention(\n",
              "        (query): Depth_conv(\n",
              "          (depth_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
              "          (point_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (key): Depth_conv(\n",
              "          (depth_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
              "          (point_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (value): Depth_conv(\n",
              "          (depth_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
              "          (point_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (conv_tail): Depth_conv(\n",
              "        (depth_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
              "        (point_conv): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "    )\n",
              "    (high_enhance1): HFRM(\n",
              "      (conv_head): Depth_conv(\n",
              "        (depth_conv): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3)\n",
              "        (point_conv): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "      (dilated_block_LH): Dilated_Resblock(\n",
              "        (model): Sequential(\n",
              "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): LeakyReLU(negative_slope=0.01)\n",
              "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "          (3): LeakyReLU(negative_slope=0.01)\n",
              "          (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))\n",
              "          (5): LeakyReLU(negative_slope=0.01)\n",
              "          (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "          (7): LeakyReLU(negative_slope=0.01)\n",
              "          (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (dilated_block_HL): Dilated_Resblock(\n",
              "        (model): Sequential(\n",
              "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): LeakyReLU(negative_slope=0.01)\n",
              "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "          (3): LeakyReLU(negative_slope=0.01)\n",
              "          (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))\n",
              "          (5): LeakyReLU(negative_slope=0.01)\n",
              "          (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "          (7): LeakyReLU(negative_slope=0.01)\n",
              "          (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (cross_attention0): cross_attention(\n",
              "        (query): Depth_conv(\n",
              "          (depth_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
              "          (point_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (key): Depth_conv(\n",
              "          (depth_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
              "          (point_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (value): Depth_conv(\n",
              "          (depth_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
              "          (point_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (dilated_block_HH): Dilated_Resblock(\n",
              "        (model): Sequential(\n",
              "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): LeakyReLU(negative_slope=0.01)\n",
              "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "          (3): LeakyReLU(negative_slope=0.01)\n",
              "          (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3))\n",
              "          (5): LeakyReLU(negative_slope=0.01)\n",
              "          (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "          (7): LeakyReLU(negative_slope=0.01)\n",
              "          (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (conv_HH): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (cross_attention1): cross_attention(\n",
              "        (query): Depth_conv(\n",
              "          (depth_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
              "          (point_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (key): Depth_conv(\n",
              "          (depth_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
              "          (point_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (value): Depth_conv(\n",
              "          (depth_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
              "          (point_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "      )\n",
              "      (conv_tail): Depth_conv(\n",
              "        (depth_conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
              "        (point_conv): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "    )\n",
              "    (Unet): DiffusionUNet(\n",
              "      (temb): Module(\n",
              "        (dense): ModuleList(\n",
              "          (0): Linear(in_features=64, out_features=256, bias=True)\n",
              "          (1): Linear(in_features=256, out_features=256, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (conv_in): Conv2d(6, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (down): ModuleList(\n",
              "        (0): Module(\n",
              "          (block): ModuleList(\n",
              "            (0-1): 2 x ResnetBlock(\n",
              "              (norm1): GroupNorm(32, 64, eps=1e-06, affine=True)\n",
              "              (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (temb_proj): Linear(in_features=256, out_features=64, bias=True)\n",
              "              (norm2): GroupNorm(32, 64, eps=1e-06, affine=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            )\n",
              "          )\n",
              "          (attn): ModuleList()\n",
              "          (downsample): Downsample(\n",
              "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2))\n",
              "          )\n",
              "        )\n",
              "        (1): Module(\n",
              "          (block): ModuleList(\n",
              "            (0): ResnetBlock(\n",
              "              (norm1): GroupNorm(32, 64, eps=1e-06, affine=True)\n",
              "              (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (temb_proj): Linear(in_features=256, out_features=128, bias=True)\n",
              "              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (nin_shortcut): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "            )\n",
              "            (1): ResnetBlock(\n",
              "              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
              "              (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (temb_proj): Linear(in_features=256, out_features=128, bias=True)\n",
              "              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            )\n",
              "          )\n",
              "          (attn): ModuleList()\n",
              "          (downsample): Downsample(\n",
              "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))\n",
              "          )\n",
              "        )\n",
              "        (2): Module(\n",
              "          (block): ModuleList(\n",
              "            (0): ResnetBlock(\n",
              "              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
              "              (conv1): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (temb_proj): Linear(in_features=256, out_features=192, bias=True)\n",
              "              (norm2): GroupNorm(32, 192, eps=1e-06, affine=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "              (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (nin_shortcut): Conv2d(128, 192, kernel_size=(1, 1), stride=(1, 1))\n",
              "            )\n",
              "            (1): ResnetBlock(\n",
              "              (norm1): GroupNorm(32, 192, eps=1e-06, affine=True)\n",
              "              (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (temb_proj): Linear(in_features=256, out_features=192, bias=True)\n",
              "              (norm2): GroupNorm(32, 192, eps=1e-06, affine=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "              (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            )\n",
              "          )\n",
              "          (attn): ModuleList(\n",
              "            (0-1): 2 x AttnBlock(\n",
              "              (norm): GroupNorm(32, 192, eps=1e-06, affine=True)\n",
              "              (q): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (k): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (v): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (proj_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
              "            )\n",
              "          )\n",
              "          (downsample): Downsample(\n",
              "            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2))\n",
              "          )\n",
              "        )\n",
              "        (3): Module(\n",
              "          (block): ModuleList(\n",
              "            (0): ResnetBlock(\n",
              "              (norm1): GroupNorm(32, 192, eps=1e-06, affine=True)\n",
              "              (conv1): Conv2d(192, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (temb_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (nin_shortcut): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "            )\n",
              "            (1): ResnetBlock(\n",
              "              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
              "              (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (temb_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "            )\n",
              "          )\n",
              "          (attn): ModuleList()\n",
              "        )\n",
              "      )\n",
              "      (mid): Module(\n",
              "        (block_1): ResnetBlock(\n",
              "          (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
              "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (temb_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "        (attn_1): AttnBlock(\n",
              "          (norm): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
              "          (q): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (k): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (v): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (proj_out): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (block_2): ResnetBlock(\n",
              "          (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
              "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (temb_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (up): ModuleList(\n",
              "        (0): Module(\n",
              "          (block): ModuleList(\n",
              "            (0): ResnetBlock(\n",
              "              (norm1): GroupNorm(32, 192, eps=1e-06, affine=True)\n",
              "              (conv1): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (temb_proj): Linear(in_features=256, out_features=64, bias=True)\n",
              "              (norm2): GroupNorm(32, 64, eps=1e-06, affine=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (nin_shortcut): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "            )\n",
              "            (1-2): 2 x ResnetBlock(\n",
              "              (norm1): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
              "              (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (temb_proj): Linear(in_features=256, out_features=64, bias=True)\n",
              "              (norm2): GroupNorm(32, 64, eps=1e-06, affine=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (nin_shortcut): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "            )\n",
              "          )\n",
              "          (attn): ModuleList()\n",
              "        )\n",
              "        (1): Module(\n",
              "          (block): ModuleList(\n",
              "            (0): ResnetBlock(\n",
              "              (norm1): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
              "              (conv1): Conv2d(320, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (temb_proj): Linear(in_features=256, out_features=128, bias=True)\n",
              "              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (nin_shortcut): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "            )\n",
              "            (1): ResnetBlock(\n",
              "              (norm1): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
              "              (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (temb_proj): Linear(in_features=256, out_features=128, bias=True)\n",
              "              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (nin_shortcut): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "            )\n",
              "            (2): ResnetBlock(\n",
              "              (norm1): GroupNorm(32, 192, eps=1e-06, affine=True)\n",
              "              (conv1): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (temb_proj): Linear(in_features=256, out_features=128, bias=True)\n",
              "              (norm2): GroupNorm(32, 128, eps=1e-06, affine=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (nin_shortcut): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "            )\n",
              "          )\n",
              "          (attn): ModuleList()\n",
              "          (upsample): Upsample(\n",
              "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (2): Module(\n",
              "          (block): ModuleList(\n",
              "            (0): ResnetBlock(\n",
              "              (norm1): GroupNorm(32, 448, eps=1e-06, affine=True)\n",
              "              (conv1): Conv2d(448, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (temb_proj): Linear(in_features=256, out_features=192, bias=True)\n",
              "              (norm2): GroupNorm(32, 192, eps=1e-06, affine=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "              (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (nin_shortcut): Conv2d(448, 192, kernel_size=(1, 1), stride=(1, 1))\n",
              "            )\n",
              "            (1): ResnetBlock(\n",
              "              (norm1): GroupNorm(32, 384, eps=1e-06, affine=True)\n",
              "              (conv1): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (temb_proj): Linear(in_features=256, out_features=192, bias=True)\n",
              "              (norm2): GroupNorm(32, 192, eps=1e-06, affine=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "              (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (nin_shortcut): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1))\n",
              "            )\n",
              "            (2): ResnetBlock(\n",
              "              (norm1): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
              "              (conv1): Conv2d(320, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (temb_proj): Linear(in_features=256, out_features=192, bias=True)\n",
              "              (norm2): GroupNorm(32, 192, eps=1e-06, affine=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "              (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (nin_shortcut): Conv2d(320, 192, kernel_size=(1, 1), stride=(1, 1))\n",
              "            )\n",
              "          )\n",
              "          (attn): ModuleList(\n",
              "            (0-2): 3 x AttnBlock(\n",
              "              (norm): GroupNorm(32, 192, eps=1e-06, affine=True)\n",
              "              (q): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (k): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (v): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (proj_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
              "            )\n",
              "          )\n",
              "          (upsample): Upsample(\n",
              "            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (3): Module(\n",
              "          (block): ModuleList(\n",
              "            (0-1): 2 x ResnetBlock(\n",
              "              (norm1): GroupNorm(32, 512, eps=1e-06, affine=True)\n",
              "              (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (temb_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (nin_shortcut): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "            )\n",
              "            (2): ResnetBlock(\n",
              "              (norm1): GroupNorm(32, 448, eps=1e-06, affine=True)\n",
              "              (conv1): Conv2d(448, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (temb_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (norm2): GroupNorm(32, 256, eps=1e-06, affine=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (nin_shortcut): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "            )\n",
              "          )\n",
              "          (attn): ModuleList()\n",
              "          (upsample): Upsample(\n",
              "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (norm_out): GroupNorm(32, 64, eps=1e-06, affine=True)\n",
              "      (conv_out): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vH3k18epZd9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 入力画像読み込み・前処理\n",
        "image_path = \"/content/drive/MyDrive/Colab Notebooks/Data/Panorama/living_dark_768.jpg\"\n",
        "image_path = \"/content/drive/MyDrive/Colab Notebooks/Data/dark_normal_picture.jpg\"\n",
        "image = Image.open(image_path).convert(\"RGB\")\n",
        "print(image.size)\n",
        "\n",
        "# T.ToTensor()\tPIL画像（H×W×Cの範囲0〜255）を、PyTorch用のテンソル（C×H×W、値は0.0〜1.0）に変換\n",
        "# T.ToTensor()(image)\timage をテンソル化（例：torch.Size([3, 768, 1536])）\n",
        "# .unsqueeze(0)\tミニバッチ次元（B=1）を追加 → torch.Size([1, 3, 768, 1536])\n",
        "# .cuda()\tテンソルを GPU（CUDAデバイス）に転送\n",
        "input_tensor = T.ToTensor()(image).unsqueeze(0).cuda()\n",
        "\n",
        "# 推論\n",
        "with torch.no_grad():\n",
        "    output = model.model(input_tensor)\n",
        "    restored_image = output[\"pred_x\"]\n",
        "\n",
        "# 保存\n",
        "basename = os.path.basename(image_path)\n",
        "name, _ = os.path.splitext(basename)\n",
        "output_path = f\"{name}_restored.jpg\"\n",
        "\n",
        "# restored_image\tモデル出力（shape: [1, 3, H, W]）\n",
        "# .squeeze(0)\tバッチ次元 1 を削除 → [3, H, W]\n",
        "# .cpu()\tGPU→CPU にテンソルを移動（保存処理などで必要）\n",
        "# .clamp(0, 1)\t値を 0〜1の範囲に制限（画像なのでこの範囲を超えると不正になるため）\n",
        "T.ToPILImage()(restored_image.squeeze(0).cpu().clamp(0, 1)).save(output_path)\n",
        "print(f\"保存完了: {output_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_plLIGRIz0Z",
        "outputId": "6bec52a0-7acd-4f68-eb56-5d25cfed47b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(992, 576)\n",
            "保存完了: dark_normal_picture_restored.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aKQV4beBJeB_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}